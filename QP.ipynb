{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNClqgnhx2TPLomlHs+I+Mr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zanzivyr/Optimizers/blob/main/QP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quadratic Programming\n",
        "\n",
        "Today we will continue our study of optimization by writing a Quadratic Programming solver.\n",
        "\n",
        "This will be a bit more challenging than the LP Solver, but will help build understanding of different classes of optimization problems. Let's dig in!"
      ],
      "metadata": {
        "id": "tAyBgfs15eQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "These are the resources I used to learn how to solve Quadratic Programming problems.\n",
        "\n",
        "- Wikipedia - https://en.wikipedia.org/wiki/Quadratic_programming\n",
        "- Kody Powell - https://www.youtube.com/watch?v=GZb9647X8sg\n",
        "- Chris Rycroft - https://www.youtube.com/watch?v=O-pTuBTShc4\n",
        "- BYU FLOW Lab - https://youtu.be/F9aG69nn1n8\n",
        "- **BEST** -> Efstratios Nikolaidis - https://www.youtube.com/watch?v=Ifve4IpeH9w\n",
        "\n",
        "Automatic Differentiation:\n",
        "- Ari Seff - https://www.youtube.com/watch?v=wG_nF1awSSY\n"
      ],
      "metadata": {
        "id": "zTtdBeCu50OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from numpy import linalg as LA"
      ],
      "metadata": {
        "id": "4sDnHfTP6Z6P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constraints = 4 # m\n",
        "variables = 2 # n\n",
        "\n",
        "# Q must be Symmetric Positive Definite\n",
        "# Q is n x n\n",
        "Q = tf.random.normal(\n",
        "    shape=[variables, variables],\n",
        "    mean=0,\n",
        "    stddev=1,\n",
        "    dtype=tf.dtypes.float32,\n",
        "    seed=42,\n",
        "    name=None\n",
        ")\n",
        "# f is n x 1\n",
        "f = tf.random.normal(\n",
        "    shape=[variables, 1],\n",
        "    mean=0,\n",
        "    stddev=1,\n",
        "    dtype=tf.dtypes.float32,\n",
        "    seed=32,\n",
        "    name=None\n",
        ")\n",
        "# A is m x n\n",
        "A = tf.random.normal(\n",
        "    shape=[constraints, variables],\n",
        "    mean=0,\n",
        "    stddev=1,\n",
        "    dtype=tf.dtypes.float32,\n",
        "    seed=22,\n",
        "    name=None\n",
        ")\n",
        "# b is m x 1\n",
        "b = tf.random.normal(\n",
        "    shape=[constraints, 1],\n",
        "    mean=0,\n",
        "    stddev=1,\n",
        "    dtype=tf.dtypes.float32,\n",
        "    seed=12,\n",
        "    name=None\n",
        ")\n",
        "# solution is (m + n) x 1\n",
        "sol = np.concatenate([-f, -b], 0)\n",
        "\n",
        "Q, f, A, b, sol.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7UejiGEnBle",
        "outputId": "9cf6a59e-a706-4fb5-e817-667b7e984603"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[-1.4677944 ,  1.0870852 ],\n",
              "        [ 0.94264466, -0.40158314]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              " array([[2.082934],\n",
              "        [1.77611 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              " array([[ 0.16568154, -3.0080743 ],\n",
              "        [-0.6044153 , -0.10841811],\n",
              "        [-0.20918587, -0.71651995],\n",
              "        [ 0.16861683,  1.3579242 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
              " array([[-1.0506643 ],\n",
              "        [ 0.6807904 ],\n",
              "        [-0.11149635],\n",
              "        [ 0.06687231]], dtype=float32)>,\n",
              " (6, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R1 = tf.concat([Q, A], 0)\n",
        "\n",
        "# Create right side of Jacobian matrix\n",
        "# Add appropriate number of rows of zeroes\n",
        "R2 = A\n",
        "if A.shape[1] != R1.shape[0]:\n",
        "  R2 = tf.concat([A, tf.zeros([constraints, A.shape[0]], tf.float32)], 1)\n",
        "\n",
        "R = tf.concat([R1, np.transpose(R2)], 1)\n",
        "R.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvFQwyXroTN7",
        "outputId": "863b9a37-0001-4f25-9ee5-238bc69e88e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Singular Value Decomposition\n",
        "\n",
        "We will use SVD to decompose and invert our R matrix containing the Hessian of the Lagrangian, A, and A transpose."
      ],
      "metadata": {
        "id": "ewVmC22oIx-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD\n",
        "u, s, vt = np.linalg.svd(R, full_matrices=True)\n",
        "u.shape, s.shape, vt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G0pelVYLFzV",
        "outputId": "5fd346d9-be1d-40dd-b180-cd62debe1b7f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6, 6), (6,), (6, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moore-Penrose Pseudo Inverse\n",
        "vtt = np.transpose(vt)\n",
        "s = np.linalg.inv(np.diag(s))\n",
        "ut = np.transpose(u)\n",
        "\n",
        "vtt.shape, s.shape, ut.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7zsLqicLD2P",
        "outputId": "a2322ae6-b3a5-419e-bf9d-cfc062c1d407"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6, 6), (6, 6), (6, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping\n",
        "\n",
        "Let's reshape the sigma matrix.\n",
        "\n",
        "If it's overdetermined (rows > cols), then add a column of zeroes.\n",
        "\n",
        "If it's underdetermined (cols > rows), then add a row of zeroes."
      ],
      "metadata": {
        "id": "l8SmmecCLnIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overdetermined\n",
        "# Concat extra column of zeroes\n",
        "if R.shape[0] > R.shape[1]:\n",
        "  print(\"Overdetermined\")\n",
        "  sinv = np.concatenate(\n",
        "      (\n",
        "          s, \n",
        "          tf.zeros([s.shape[0], 1], tf.float32)\n",
        "      ), \n",
        "      axis=1\n",
        "  )\n",
        "# Underdetermined\n",
        "# Concat extra row of zeroes\n",
        "elif R.shape[0] < R.shape[1]:\n",
        "  print(\"Underdetermined\")\n",
        "  sinv = np.concatenate(\n",
        "      (\n",
        "          s, \n",
        "          tf.zeros([1, s.shape[1]], tf.float32)\n",
        "      ), \n",
        "      axis=0\n",
        "  )\n",
        "else:\n",
        "  sinv = s\n",
        "\n",
        "sinv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyS8aJjKK__8",
        "outputId": "2ce442aa-2a70-4219-f42e-b820f8bb40b7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, given the linear affine equation, solve for the step column vector."
      ],
      "metadata": {
        "id": "y4hXf5noIhDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Adag = np.dot(vtt, np.dot(sinv, ut))\n",
        "step = np.dot(Adag, sol)\n",
        "step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCKeqTRbvKPs",
        "outputId": "95b1f291-1bdd-4442-8e24-ca4c32117f6d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.1524588e+00],\n",
              "       [ 3.4936219e-03],\n",
              "       [-1.5648152e+15],\n",
              "       [ 6.5487091e+14],\n",
              "       [-1.0237997e+16],\n",
              "       [-8.8162579e+15]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "Assuming that Q is Symmetric and Positive Definite, and the Hessian of the Lagrangian contains only linear terms, then we can stop here.\n",
        "\n",
        "Below is our solution for x given the Lagrange multiplier, lambda."
      ],
      "metadata": {
        "id": "JFlwjYalID-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sx = step[0:variables,:]\n",
        "sx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrJW92m-iN0o",
        "outputId": "be9dd359-704a-4212-a667-ff06338bea35"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1524588 ],\n",
              "       [0.00349362]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slmda = step[variables:,:]\n",
        "slmda"
      ],
      "metadata": {
        "id": "wIruYcVjMwUL",
        "outputId": "e45b9ff1-701f-49b3-e415-3ced4d1ab829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.5648152e+15],\n",
              "       [ 6.5487091e+14],\n",
              "       [-1.0237997e+16],\n",
              "       [-8.8162579e+15]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Linear Hessians\n",
        "\n",
        "If the Hessian of the Lagranian contains non-linear terms then we will not be able to differentiate out our decision variables. \n",
        "\n",
        "This means that step values for x and lambda will need to be substituted back into the overall matrix, R (Rs = d, where R = [ [Q Aᵀ], [A 0] ], s = [x, λ], and d = [-f, -b]), before solving again for s and continuing to step towards the optimum.\n",
        "\n",
        "I believe this requires using Automatic Differentiation, which is a topic wholly different from Quadratic Programming, and I will leave for another project."
      ],
      "metadata": {
        "id": "sUtoOk0J8Gjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter = 0 # Need to implement Automatic Differentiation\n",
        "thresh = 0.01\n",
        "\n",
        "lmda = 0\n",
        "\n",
        "J = 0\n",
        "Jprev = 0\n",
        "L2 = 0\n",
        "L2prev = 0\n",
        "\n",
        "# initial guess\n",
        "x = tf.random.normal(\n",
        "    shape=[variables, 1],\n",
        "    mean=0,\n",
        "    stddev=1,\n",
        "    dtype=tf.dtypes.float32,\n",
        "    seed=2,\n",
        "    name=None\n",
        ")\n",
        "\n",
        "for i in range(iter):\n",
        "  J = np.dot(np.transpose(x), np.dot(Q, x)) + np.dot(np.transpose(f), x)\n",
        "  L2 = LA.norm(sx, axis=0)\n",
        "\n",
        "  slope = (J - Jprev) / (L2 - L2prev)\n",
        "  \n",
        "  Jprev = J\n",
        "  L2prev = L2\n",
        "\n",
        "  # Need to reduce Hessian of Lagrangian using previous step \n",
        "  #  values for x and lambda to find new step value for x and lambda.\n",
        "  \n",
        "  # If the Hessian contains non-linear terms, then I believe this \n",
        "  #  cannot be done without Automatic Differentiation.\n",
        "\n",
        "  # We will leave this as a task for another project.\n",
        "  x = x + sx\n",
        "  lmda = lmda + slmda\n",
        "\n",
        "  if slope < thresh:\n",
        "    print(\"Found optimal value!\")\n",
        "    break\n",
        "\n",
        "'''\n",
        "print(\"Optimal cost is: \" + str(J))\n",
        "print(\"with x as: \")\n",
        "print(x)\n",
        "print(\"and lambda as: \")\n",
        "print(lmda)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jSt_Z5WAoCaY",
        "outputId": "b2efe232-277b-4a8a-e237-1edb2b08ecfd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Optimal cost is: \" + str(J))\\nprint(\"with x as: \")\\nprint(x)\\nprint(\"and lambda as: \")\\nprint(lmda)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cqmuSsstMALh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}